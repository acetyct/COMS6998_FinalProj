{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cqsw0IP65J9B",
    "outputId": "6e705b43-17d7-401a-fadd-11cd72e64af9"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import tempfile\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import CSVLogger  #, UpdatePruningStep\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from keras.datasets import cifar100\n",
    "import tensorflow as tf\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmCFZ9uR6lyN",
    "outputId": "67d18fc5-6fe6-47fc-83d1-97d707f93652"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-model-optimization\n",
      "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.14 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (1.21.6)\n",
      "Requirement already satisfied: six~=1.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (1.16.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (0.1.7)\n",
      "Installing collected packages: tensorflow-model-optimization\n",
      "Successfully installed tensorflow-model-optimization-0.7.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wau5tD8v5MHl"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "import multiprocessing\n",
    "import os\n",
    "import random\n",
    "#import portpicker\n",
    "#import hypertune\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f3u6BwEZ5Ngo"
   },
   "outputs": [],
   "source": [
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OJNDDDzn5Qyy",
    "outputId": "155abd49-1dab-4d05-a33d-9aa8be71cf9c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 05:32:31.905911: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:32.841486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:32.841970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:33.024132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-17 05:32:33.049520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:33.049908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:33.050101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:40.377643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:40.399836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:40.400280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-12-17 05:32:40.400484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14626 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")  #   tf.distribute.experimental.CentralStorageStrategy()   #tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8xlQL90G5SzL"
   },
   "outputs": [],
   "source": [
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q0qeB2wJ5nsX"
   },
   "outputs": [],
   "source": [
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KI--slgF5-D0"
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "jtXh5ajC6AKC"
   },
   "outputs": [],
   "source": [
    "def tflite_conv(model,path,quant=False):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    if quant == True:\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    pruned_tflite_model = converter.convert()\n",
    "    with open(path, 'wb') as f:\n",
    "      f.write(pruned_tflite_model)\n",
    "    print('Saved pruned TFLite model to:',path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "GQ4jU6PM6CJV"
   },
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TqbzgNzq6EQB",
    "outputId": "b09f407c-f067-4af3-cf3c-e79a3efa8d50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "J7YmlsR26M8G"
   },
   "outputs": [],
   "source": [
    "def resnet_training(x_train,y_train,x_test, y_test,layers,frequency,\\\n",
    "                    initial_sparsity,final_sparsity,gpu=\"T4\",\\\n",
    "                    const=True, poly=False,file_name='cifar10_test1',\\\n",
    "                    num_classes=10,begin_step=0,end_step='default'):\n",
    "\n",
    "    # Default parameters\n",
    "    batch_size = 128 * strategy.num_replicas_in_sync \n",
    "    epochs = 1#300\n",
    "    data_augmentation = True\n",
    "    n = layers\n",
    "\n",
    "    # Computed depth from supplied model parameter n\n",
    "    depth = n * 6 + 2\n",
    "\n",
    "    # Input image dimensions.\n",
    "    input_shape = x_train.shape[1:]\n",
    "\n",
    "    # Subtracting pixel mean improves accuracy\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "    print('x_train shape:', x_train.shape)\n",
    "    print(x_train.shape[0], 'train samples')\n",
    "    print(x_test.shape[0], 'test samples')\n",
    "    print('y_train shape:', y_train.shape)\n",
    "\n",
    "    ####Changes start#####\n",
    "    num_images = x_train.shape[0] #* (1 - validation_split)\n",
    "\n",
    "    if end_step == 'default':\n",
    "        end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "    #hyperparameters: initial_sparsity=0.50, final_sparsity=0.80\n",
    "    if poly:\n",
    "        pruning_params = {\n",
    "              'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n",
    "                                                                       final_sparsity=final_sparsity,\n",
    "                                                                       begin_step=begin_step,\n",
    "                                                                       end_step=end_step,\n",
    "                                                                      frequency=frequency)\n",
    "        }\n",
    "    if const:\n",
    "            pruning_params = {\n",
    "              'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=final_sparsity,\n",
    "                                                                       begin_step=begin_step,\n",
    "                                                                       end_step=end_step,\n",
    "                                                                       frequency=frequency)\n",
    "        }\n",
    "\n",
    "    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "    with strategy.scope():\n",
    "        model = resnet_v1(input_shape=input_shape, depth=depth,num_classes=num_classes)\n",
    "        model = prune_low_magnitude(model, **pruning_params)    #_for_pruning\n",
    "\n",
    "        model.compile(loss= 'categorical_crossentropy',     #''  tf.  keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "                  optimizer=Adam(lr=lr_schedule(0)),\n",
    "                  metrics=['accuracy'])\n",
    "    ####Changes end#####\n",
    "    model.summary()\n",
    "\n",
    "    # Prepare model model saving directory.\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    model_run=file_name+'_'+str(depth)+'_'+gpu\n",
    "    model_path=model_run+'.h5'\n",
    "    print(\"RRrrrrrR\",model_path)\n",
    "    \n",
    "    filepath = os.path.join(save_dir, model_path)\n",
    "    print(\"RRR\",filepath)\n",
    "    \n",
    "    print(model_run)\n",
    "\n",
    "    # Prepare callbacks for model saving and for learning rate adjustment.\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                                 monitor='val_acc',\n",
    "                                 verbose=1,\n",
    "                                 save_best_only=True)\n",
    "\n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                                   cooldown=0,\n",
    "                                   patience=5,\n",
    "                                   min_lr=0.5e-6)\n",
    "    logdir = tempfile.mkdtemp()\n",
    "    time_callback = TimeHistory()\n",
    "    logname='/home/jupyter/final_proj/log_'+model_run+'.csv'\n",
    "    csv_logger = CSVLogger(logname, append=True, separator=';')\n",
    "    callbacks = [checkpoint, lr_reducer, lr_scheduler, csv_logger, time_callback, pruning_callbacks.UpdatePruningStep(), tfmot.sparsity.keras.PruningSummaries(log_dir=logdir)]\n",
    "\n",
    "    st = time.time()\n",
    "    ######################## no augmentation################\n",
    "    # model.fit(x_train, y_train,\n",
    "    #           batch_size=batch_size,\n",
    "    #           epochs=epochs,\n",
    "    #           validation_data=(x_test, y_test),\n",
    "    #           shuffle=True,\n",
    "    #           callbacks=callbacks)\n",
    "    ######################## no augmentation################\n",
    "\n",
    "    ########################augmentation################\n",
    "    datagen = ImageDataGenerator(\n",
    "          # set input mean to 0 over the dataset\n",
    "          featurewise_center=False,\n",
    "          # set each sample mean to 0\n",
    "          samplewise_center=False,\n",
    "          # divide inputs by std of dataset\n",
    "          featurewise_std_normalization=False,\n",
    "          # divide each input by its std\n",
    "          samplewise_std_normalization=False,\n",
    "          # apply ZCA whitening\n",
    "          zca_whitening=False,\n",
    "          # epsilon for ZCA whitening\n",
    "          zca_epsilon=1e-06,\n",
    "          # randomly rotate images in the range (deg 0 to 180)\n",
    "          rotation_range=0,\n",
    "          # randomly shift images horizontally\n",
    "          width_shift_range=0.1,\n",
    "          # randomly shift images vertically\n",
    "          height_shift_range=0.1,\n",
    "          # set range for random shear\n",
    "          shear_range=0.,\n",
    "          # set range for random zoom\n",
    "          zoom_range=0.,\n",
    "          # set range for random channel shifts\n",
    "          channel_shift_range=0.,\n",
    "          # set mode for filling points outside the input boundaries\n",
    "          fill_mode='nearest',\n",
    "          # value used for fill_mode = \"constant\"\n",
    "          cval=0.,\n",
    "          # randomly flip images\n",
    "          horizontal_flip=True,\n",
    "          # randomly flip images\n",
    "          vertical_flip=False,\n",
    "          # set rescaling factor (applied before any other transformation)\n",
    "          rescale=None,\n",
    "          # set function that will be applied on each input\n",
    "          preprocessing_function=None,\n",
    "          # image data format, either \"channels_first\" or \"channels_last\"\n",
    "          data_format=None,\n",
    "          # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "          validation_split=0.0)\n",
    "          \n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, \n",
    "                        callbacks=callbacks)\n",
    "     \n",
    "     ########################augmentation################\n",
    "\n",
    "    %tensorboard --logdir={logdir}\n",
    "    training_time = time.time() - st\n",
    "\n",
    "    print(f\"overall training time is {training_time}\")\n",
    "    epoch_times = time_callback.times\n",
    "    print(f\"each epoch training time is {epoch_times}\")\n",
    "\n",
    "    # Score trained model.\n",
    "    scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', scores[0])\n",
    "    print('Test accuracy:', scores[1])\n",
    "    print(\"tt\",save_dir+'/'+model_run)\n",
    "    \n",
    "    #save standard model \n",
    "    model.save(save_dir+'/'+model_path)\n",
    "    \n",
    "    #saving data \n",
    "    with open(model_run+'.pickle', 'wb') as handle:\n",
    "        pickle.dump([training_time,epoch_times,scores[0],scores[1]], handle)\n",
    "\n",
    "    #save pruned model\n",
    "    model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n",
    "    pruned_keras_file = save_dir+'/PRUNE_'+model_path\n",
    "    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "    print('Saved pruned Keras model to:', pruned_keras_file)\n",
    "    \n",
    "    #convert to tflite+ save\n",
    "    pruned_tflite_file=save_dir+'/lite_PRUNE_'+model_path\n",
    "    tflite_conv(model,pruned_tflite_file)\n",
    "    \n",
    "    #save to tf lite + qaunt\n",
    "    pruned_tflite_quant_file=save_dir+'/lite_quant_PRUNE_'+model_path\n",
    "    tflite_conv(model,pruned_tflite_quant_file,quant=True)\n",
    "    \n",
    "    pruned=get_gzipped_model_size(pruned_keras_file)\n",
    "    tflite_pruned=get_gzipped_model_size(pruned_tflite_file)\n",
    "    tflite_quant_pruned=get_gzipped_model_size(pruned_tflite_quant_file)\n",
    "    \n",
    "    \n",
    "    print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (pruned))\n",
    "    print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (tflite_pruned))\n",
    "    print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (tflite_quant_pruned))\n",
    "    \n",
    "    with open(model_run+'.pickle', 'wb') as handle:\n",
    "        pickle.dump([training_time,epoch_times,scores[0],scores[1],pruned,tflite_pruned,tflite_quant_pruned], handle)\n",
    "\n",
    "    return(model,model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "XRxSJSxR6QKd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "169001437/169001437 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load the CIFAR100 data.\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
    "# Normalize data.\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "# Convert class vectors to binary class matrices.\n",
    "Y_train = keras.utils.to_categorical(Y_train)\n",
    "Y_test = keras.utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVVvxo1P6T2o",
    "outputId": "100386a8-40c4-4576-b759-69831fcee326"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 100)\n",
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d (Pr  (None, 32, 32, 16)  882         ['input_1[0][0]']                \n",
      " uneLowMagnitude)                                                                                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d[0][0\n",
      " alization (PruneLowMagnitude)                                   ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      "  (PruneLowMagnitude)                                            lization[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_1 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation[\n",
      " PruneLowMagnitude)                                              0][0]']                          \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_1[0]\n",
      " alization_1 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _1 (PruneLowMagnitude)                                          lization_1[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_2 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              1[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_2[0]\n",
      " alization_2 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add (Prune  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation[\n",
      " LowMagnitude)                                                   0][0]',                          \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_2[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add[0][0]']\n",
      " _2 (PruneLowMagnitude)                                                                           \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_3 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              2[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_3[0]\n",
      " alization_3 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _3 (PruneLowMagnitude)                                          lization_3[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_4 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              3[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_4[0]\n",
      " alization_4 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_1 (Pru  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 2[0][0]',                        \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_4[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_1[0][0]\n",
      " _4 (PruneLowMagnitude)                                          ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_5 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              4[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_5[0]\n",
      " alization_5 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _5 (PruneLowMagnitude)                                          lization_5[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_6 (  (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              5[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_6[0]\n",
      " alization_6 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_2 (Pru  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 4[0][0]',                        \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_6[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_2[0][0]\n",
      " _6 (PruneLowMagnitude)                                          ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_7 (  (None, 16, 16, 32)  9250        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              6[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_7[0]\n",
      " alization_7 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _7 (PruneLowMagnitude)                                          lization_7[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_8 (  (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              7[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_9 (  (None, 16, 16, 32)  1058        ['prune_low_magnitude_activation_\n",
      " PruneLowMagnitude)                                              6[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_8[0]\n",
      " alization_8 (PruneLowMagnitude                                  [0]']                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_3 (Pru  (None, 16, 16, 32)  1           ['prune_low_magnitude_conv2d_9[0]\n",
      " neLowMagnitude)                                                 [0]',                            \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_8[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_3[0][0]\n",
      " _8 (PruneLowMagnitude)                                          ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_10   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             8[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_10[0\n",
      " alization_9 (PruneLowMagnitude                                  ][0]']                           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _9 (PruneLowMagnitude)                                          lization_9[0][0]']               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_11   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             9[0][0]']                        \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_11[0\n",
      " alization_10 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_4 (Pru  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 8[0][0]',                        \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_10[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_4[0][0]\n",
      " _10 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_12   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             10[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_12[0\n",
      " alization_11 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _11 (PruneLowMagnitude)                                         lization_11[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_13   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             11[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_13[0\n",
      " alization_12 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_5 (Pru  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 10[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_12[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_5[0][0]\n",
      " _12 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_14   (None, 8, 8, 64)    36930       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             12[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_14[0\n",
      " alization_13 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _13 (PruneLowMagnitude)                                         lization_13[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_15   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             13[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_16   (None, 8, 8, 64)    4162        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             12[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_15[0\n",
      " alization_14 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_6 (Pru  (None, 8, 8, 64)    1           ['prune_low_magnitude_conv2d_16[0\n",
      " neLowMagnitude)                                                 ][0]',                           \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_14[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_6[0][0]\n",
      " _14 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_17   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             14[0][0]']                       \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_17[0\n",
      " alization_15 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _15 (PruneLowMagnitude)                                         lization_15[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_18   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             15[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_18[0\n",
      " alization_16 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_7 (Pru  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 14[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_16[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_7[0][0]\n",
      " _16 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_19   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             16[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_19[0\n",
      " alization_17 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _17 (PruneLowMagnitude)                                         lization_17[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_20   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             17[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_20[0\n",
      " alization_18 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_8 (Pru  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 16[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_18[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_8[0][0]\n",
      " _18 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_average_po  (None, 1, 1, 64)    1           ['prune_low_magnitude_activation_\n",
      " oling2d (PruneLowMagnitude)                                     18[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatten (P  (None, 64)          1           ['prune_low_magnitude_average_poo\n",
      " runeLowMagnitude)                                               ling2d[0][0]']                   \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense (Pru  (None, 100)         12902       ['prune_low_magnitude_flatten[0][\n",
      " neLowMagnitude)                                                 0]']                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 557,041\n",
      "Trainable params: 278,916\n",
      "Non-trainable params: 278,125\n",
      "__________________________________________________________________________________________________\n",
      "RRrrrrrR resnet_super_twenty1_20_k80.h5\n",
      "RRR /home/jupyter/saved_models/resnet_super_twenty1_20_k80.h5\n",
      "resnet_super_twenty1_20_k80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:153: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "2022-12-17 05:35:37.041698: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_2500\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-17 05:36:14.009622: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/391 [..............................] - ETA: 16s - loss: 6.5702 - accuracy: 0.0143  WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0389s vs `on_train_batch_end` time: 0.0909s). Check your callbacks.\n",
      "391/391 [==============================] - ETA: 0s - loss: 4.2331 - accuracy: 0.0876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "391/391 [==============================] - 95s 87ms/step - loss: 4.2331 - accuracy: 0.0876 - val_loss: 4.0438 - val_accuracy: 0.0934 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3b2a1e7e91ab5b24\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3b2a1e7e91ab5b24\");\n",
       "          const url = new URL(\"/proxy/6006/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall training time is 103.38009071350098\n",
      "each epoch training time is [95.42731380462646]\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 4.0438 - accuracy: 0.0934\n",
      "Test loss: 4.0438127517700195\n",
      "Test accuracy: 0.0934000015258789\n",
      "tt /home/jupyter/saved_models/resnet_super_twenty1_20_k80\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved pruned Keras model to: /home/jupyter/saved_models/PRUNE_resnet_super_twenty1_20_k80.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnhudxszf/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpnhudxszf/assets\n",
      "2022-12-17 05:38:40.089778: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-12-17 05:38:40.089855: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-12-17 05:38:40.091004: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmpnhudxszf\n",
      "2022-12-17 05:38:40.163013: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-12-17 05:38:40.163092: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmpnhudxszf\n",
      "2022-12-17 05:38:40.412373: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-12-17 05:38:40.503597: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-12-17 05:38:41.560674: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmpnhudxszf\n",
      "2022-12-17 05:38:41.918955: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 1827955 microseconds.\n",
      "2022-12-17 05:38:43.277978: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/jupyter/saved_models/lite_PRUNE_resnet_super_twenty1_20_k80.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as conv2d_layer_call_fn, conv2d_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, activation_layer_call_fn, activation_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp12go250x/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp12go250x/assets\n",
      "2022-12-17 05:39:59.445890: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n",
      "2022-12-17 05:39:59.445964: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n",
      "2022-12-17 05:39:59.446170: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmp12go250x\n",
      "2022-12-17 05:39:59.523299: I tensorflow/cc/saved_model/reader.cc:89] Reading meta graph with tags { serve }\n",
      "2022-12-17 05:39:59.523394: I tensorflow/cc/saved_model/reader.cc:130] Reading SavedModel debug info (if present) from: /tmp/tmp12go250x\n",
      "2022-12-17 05:39:59.898280: I tensorflow/cc/saved_model/loader.cc:229] Restoring SavedModel bundle.\n",
      "2022-12-17 05:40:00.894854: I tensorflow/cc/saved_model/loader.cc:213] Running initialization op on SavedModel bundle at path: /tmp/tmp12go250x\n",
      "2022-12-17 05:40:01.271877: I tensorflow/cc/saved_model/loader.cc:305] SavedModel load for tags { serve }; Status: success: OK. Took 1825707 microseconds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/jupyter/saved_models/lite_quant_PRUNE_resnet_super_twenty1_20_k80.h5\n",
      "Size of gzipped pruned Keras model: 564095.00 bytes\n",
      "Size of gzipped pruned TFlite model: 621542.00 bytes\n",
      "Size of gzipped pruned and quantized TFlite model: 621567.00 bytes\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 100)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_21   (None, 32, 32, 16)  882         ['input_2[0][0]']                \n",
      " (PruneLowMagnitude)                                                                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_21[0\n",
      " alization_19 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _19 (PruneLowMagnitude)                                         lization_19[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_22   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             19[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_22[0\n",
      " alization_20 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _20 (PruneLowMagnitude)                                         lization_20[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_23   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             20[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_23[0\n",
      " alization_21 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_9 (Pru  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " neLowMagnitude)                                                 19[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_21[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_9[0][0]\n",
      " _21 (PruneLowMagnitude)                                         ']                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_24   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             21[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_24[0\n",
      " alization_22 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _22 (PruneLowMagnitude)                                         lization_22[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_25   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             22[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_25[0\n",
      " alization_23 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_10 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                21[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_23[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_10[0][0\n",
      " _23 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_26   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             23[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_26[0\n",
      " alization_24 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _24 (PruneLowMagnitude)                                         lization_24[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_27   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             24[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_27[0\n",
      " alization_25 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_11 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                23[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_25[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_11[0][0\n",
      " _25 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_28   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             25[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_28[0\n",
      " alization_26 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _26 (PruneLowMagnitude)                                         lization_26[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_29   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             26[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_29[0\n",
      " alization_27 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_12 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                25[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_27[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_12[0][0\n",
      " _27 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_30   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             27[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_30[0\n",
      " alization_28 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _28 (PruneLowMagnitude)                                         lization_28[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_31   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             28[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_31[0\n",
      " alization_29 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_13 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                27[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_29[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_13[0][0\n",
      " _29 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_32   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             29[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_32[0\n",
      " alization_30 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _30 (PruneLowMagnitude)                                         lization_30[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_33   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             30[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_33[0\n",
      " alization_31 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_14 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                29[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_31[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_14[0][0\n",
      " _31 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_34   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             31[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_34[0\n",
      " alization_32 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n",
      " _32 (PruneLowMagnitude)                                         lization_32[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_35   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             32[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_35[0\n",
      " alization_33 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_15 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                31[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_33[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_15[0][0\n",
      " _33 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_36   (None, 16, 16, 32)  9250        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             33[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_36[0\n",
      " alization_34 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _34 (PruneLowMagnitude)                                         lization_34[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_37   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             34[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_38   (None, 16, 16, 32)  1058        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             33[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_37[0\n",
      " alization_35 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_16 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_conv2d_38[0\n",
      " uneLowMagnitude)                                                ][0]',                           \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_35[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_16[0][0\n",
      " _35 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_39   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             35[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_39[0\n",
      " alization_36 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _36 (PruneLowMagnitude)                                         lization_36[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_40   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             36[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_40[0\n",
      " alization_37 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_17 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                35[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_37[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_17[0][0\n",
      " _37 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_41   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             37[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_41[0\n",
      " alization_38 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _38 (PruneLowMagnitude)                                         lization_38[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_42   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             38[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_42[0\n",
      " alization_39 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_18 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                37[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_39[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_18[0][0\n",
      " _39 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_43   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             39[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_43[0\n",
      " alization_40 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _40 (PruneLowMagnitude)                                         lization_40[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_44   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             40[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_44[0\n",
      " alization_41 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_19 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                39[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_41[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_19[0][0\n",
      " _41 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_45   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             41[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_45[0\n",
      " alization_42 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _42 (PruneLowMagnitude)                                         lization_42[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_46   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             42[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_46[0\n",
      " alization_43 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_20 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                41[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_43[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_20[0][0\n",
      " _43 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_47   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             43[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_47[0\n",
      " alization_44 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _44 (PruneLowMagnitude)                                         lization_44[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_48   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             44[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_48[0\n",
      " alization_45 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_21 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                43[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_45[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_21[0][0\n",
      " _45 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_49   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             45[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_49[0\n",
      " alization_46 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n",
      " _46 (PruneLowMagnitude)                                         lization_46[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_50   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             46[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_50[0\n",
      " alization_47 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_22 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                45[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_47[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_22[0][0\n",
      " _47 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_51   (None, 8, 8, 64)    36930       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             47[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_51[0\n",
      " alization_48 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _48 (PruneLowMagnitude)                                         lization_48[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_52   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             48[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_53   (None, 8, 8, 64)    4162        ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             47[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_52[0\n",
      " alization_49 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_23 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_conv2d_53[0\n",
      " uneLowMagnitude)                                                ][0]',                           \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_49[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_23[0][0\n",
      " _49 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_54   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             49[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_54[0\n",
      " alization_50 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _50 (PruneLowMagnitude)                                         lization_50[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_55   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             50[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_55[0\n",
      " alization_51 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_24 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                49[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_51[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_24[0][0\n",
      " _51 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_56   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             51[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_56[0\n",
      " alization_52 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _52 (PruneLowMagnitude)                                         lization_52[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_57   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             52[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_57[0\n",
      " alization_53 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_25 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                51[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_53[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_25[0][0\n",
      " _53 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_58   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             53[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_58[0\n",
      " alization_54 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _54 (PruneLowMagnitude)                                         lization_54[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_59   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             54[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_59[0\n",
      " alization_55 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_26 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                53[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_55[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_26[0][0\n",
      " _55 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_60   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             55[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_60[0\n",
      " alization_56 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _56 (PruneLowMagnitude)                                         lization_56[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_61   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             56[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_61[0\n",
      " alization_57 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_27 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                55[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_57[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_27[0][0\n",
      " _57 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_62   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             57[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_62[0\n",
      " alization_58 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _58 (PruneLowMagnitude)                                         lization_58[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_63   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             58[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_63[0\n",
      " alization_59 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_28 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                57[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_59[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_28[0][0\n",
      " _59 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_64   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             59[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_64[0\n",
      " alization_60 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n",
      " _60 (PruneLowMagnitude)                                         lization_60[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_conv2d_65   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n",
      " (PruneLowMagnitude)                                             60[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_65[0\n",
      " alization_61 (PruneLowMagnitud                                  ][0]']                           \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " prune_low_magnitude_add_29 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n",
      " uneLowMagnitude)                                                59[0][0]',                       \n",
      "                                                                  'prune_low_magnitude_batch_norma\n",
      "                                                                 lization_61[0][0]']              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_29[0][0\n",
      " _61 (PruneLowMagnitude)                                         ]']                              \n",
      "                                                                                                  \n",
      " prune_low_magnitude_average_po  (None, 1, 1, 64)    1           ['prune_low_magnitude_activation_\n",
      " oling2d_1 (PruneLowMagnitude)                                   61[0][0]']                       \n",
      "                                                                                                  \n",
      " prune_low_magnitude_flatten_1   (None, 64)          1           ['prune_low_magnitude_average_poo\n",
      " (PruneLowMagnitude)                                             ling2d_1[0][0]']                 \n",
      "                                                                                                  \n",
      " prune_low_magnitude_dense_1 (P  (None, 100)         12902       ['prune_low_magnitude_flatten_1[0\n",
      " runeLowMagnitude)                                               ][0]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,335,773\n",
      "Trainable params: 668,676\n",
      "Non-trainable params: 667,097\n",
      "__________________________________________________________________________________________________\n",
      "RRrrrrrR resnet_super_forty1_44_k80.h5\n",
      "RRR /home/jupyter/saved_models/resnet_super_forty1_44_k80.h5\n",
      "resnet_super_forty1_44_k80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:153: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "2022-12-17 05:40:09.657167: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_204440\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\021FlatMapDataset:59\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "  6/391 [..............................] - ETA: 43s - loss: 10.1282 - accuracy: 0.0117WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1037s vs `on_train_batch_end` time: 0.2149s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1037s vs `on_train_batch_end` time: 0.2149s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - ETA: 0s - loss: 4.6453 - accuracy: 0.0703WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 89s 106ms/step - loss: 4.6453 - accuracy: 0.0703 - val_loss: 4.2543 - val_accuracy: 0.0951 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-88dabf02e95926b3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-88dabf02e95926b3\");\n",
       "          const url = new URL(\"/proxy/6007/\", window.location);\n",
       "          const port = 0;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall training time is 93.6752073764801\n",
      "each epoch training time is [88.79037761688232]\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 4.2543 - accuracy: 0.0951\n",
      "Test loss: 4.254268169403076\n",
      "Test accuracy: 0.09510000050067902\n",
      "tt /home/jupyter/saved_models/resnet_super_forty1_44_k80\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /home/jupyter/saved_models/PRUNE_resnet_super_forty1_44_k80.h5\n"
     ]
    }
   ],
   "source": [
    "layers = [3, 7]\n",
    "names = [\"twenty1\", \"forty1\"]\n",
    "for x in range(2):\n",
    "    name=\"resnet_super_\"+names[x]\n",
    "    model1 = resnet_training(X_train,Y_train,X_test, Y_test,layers=layers[x],frequency=100,\\\n",
    "                    initial_sparsity = 0.5, final_sparsity=0.6,gpu=\"V100\",\\\n",
    "                    const=False, poly=True,file_name=name,\\\n",
    "                    num_classes=100,begin_step=0,end_step='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yC-PpggqHfTm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
