{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cqsw0IP65J9B","outputId":"6e705b43-17d7-401a-fadd-11cd72e64af9"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-16 22:28:58.423515: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-16 22:29:03.443277: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2022-12-16 22:29:11.946028: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2022-12-16 22:29:11.946446: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n","2022-12-16 22:29:11.946488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"]}],"source":["from __future__ import print_function\n","import keras\n","import tempfile\n","from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n","from keras.layers import AveragePooling2D, Input, Flatten\n","from keras.optimizers import Adam\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras.callbacks import ReduceLROnPlateau\n","from keras.callbacks import CSVLogger  #, UpdatePruningStep\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.regularizers import l2\n","from keras import backend as K\n","from keras.models import Model\n","from keras.datasets import cifar10\n","from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n","import tensorflow_model_optimization as tfmot\n","import numpy as np\n","import time\n","import os\n","import pickle\n","from keras.datasets import cifar100\n","import tensorflow as tf\n","%load_ext tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UmCFZ9uR6lyN","outputId":"67d18fc5-6fe6-47fc-83d1-97d707f93652"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tensorflow-model-optimization in /home/jupyter/.local/lib/python3.7/site-packages (0.7.3)\n","Requirement already satisfied: dm-tree~=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (0.1.7)\n","Requirement already satisfied: numpy~=1.14 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (1.21.6)\n","Requirement already satisfied: six~=1.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow-model-optimization) (1.16.0)\n"]}],"source":["!pip install tensorflow-model-optimization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wau5tD8v5MHl"},"outputs":[],"source":["#@title\n","import multiprocessing\n","import os\n","import random\n","#import portpicker\n","#import hypertune\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f3u6BwEZ5Ngo"},"outputs":[],"source":["class TimeHistory(keras.callbacks.Callback):\n","    def on_train_begin(self, logs={}):\n","        self.times = []\n","\n","    def on_epoch_begin(self, batch, logs={}):\n","        self.epoch_time_start = time.time()\n","\n","    def on_epoch_end(self, batch, logs={}):\n","        self.times.append(time.time() - self.epoch_time_start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OJNDDDzn5Qyy","outputId":"155abd49-1dab-4d05-a33d-9aa8be71cf9c"},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-12-16 22:29:31.794899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:32.542555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:32.542852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:32.685383: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2022-12-16 22:29:32.707097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:32.707421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:32.707615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:41.274586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:41.287764: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:41.288185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2022-12-16 22:29:41.288446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14626 MB memory:  -> device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:00:04.0, compute capability: 7.0\n"]}],"source":["strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")  #   tf.distribute.experimental.CentralStorageStrategy()   #tf.distribute.MirroredStrategy()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8xlQL90G5SzL"},"outputs":[],"source":["def resnet_layer(inputs,\n","                 num_filters=16,\n","                 kernel_size=3,\n","                 strides=1,\n","                 activation='relu',\n","                 batch_normalization=True,\n","                 conv_first=True):\n","    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n","\n","    # Arguments\n","        inputs (tensor): input tensor from input image or previous layer\n","        num_filters (int): Conv2D number of filters\n","        kernel_size (int): Conv2D square kernel dimensions\n","        strides (int): Conv2D square stride dimensions\n","        activation (string): activation name\n","        batch_normalization (bool): whether to include batch normalization\n","        conv_first (bool): conv-bn-activation (True) or\n","            bn-activation-conv (False)\n","\n","    # Returns\n","        x (tensor): tensor as input to the next layer\n","    \"\"\"\n","    conv = Conv2D(num_filters,\n","                  kernel_size=kernel_size,\n","                  strides=strides,\n","                  padding='same',\n","                  kernel_initializer='he_normal',\n","                  kernel_regularizer=l2(1e-4))\n","\n","    x = inputs\n","    if conv_first:\n","        x = conv(x)\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","    else:\n","        if batch_normalization:\n","            x = BatchNormalization()(x)\n","        if activation is not None:\n","            x = Activation(activation)(x)\n","        x = conv(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q0qeB2wJ5nsX"},"outputs":[],"source":["def resnet_v1(input_shape, depth, num_classes=10):\n","    \"\"\"ResNet Version 1 Model builder [a]\n","\n","    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n","    Last ReLU is after the shortcut connection.\n","    At the beginning of each stage, the feature map size is halved (downsampled)\n","    by a convolutional layer with strides=2, while the number of filters is\n","    doubled. Within each stage, the layers have the same number filters and the\n","    same number of filters.\n","    Features maps sizes:\n","    stage 0: 32x32, 16\n","    stage 1: 16x16, 32\n","    stage 2:  8x8,  64\n","    The Number of parameters is approx the same as Table 6 of [a]:\n","    ResNet20 0.27M\n","    ResNet32 0.46M\n","    ResNet44 0.66M\n","    ResNet56 0.85M\n","    ResNet110 1.7M\n","\n","    # Arguments\n","        input_shape (tensor): shape of input image tensor\n","        depth (int): number of core convolutional layers\n","        num_classes (int): number of classes (CIFAR10 has 10)\n","\n","    # Returns\n","        model (Model): Keras model instance\n","    \"\"\"\n","    if (depth - 2) % 6 != 0:\n","        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n","    # Start model definition.\n","    num_filters = 16\n","    num_res_blocks = int((depth - 2) / 6)\n","\n","    inputs = Input(shape=input_shape)\n","    x = resnet_layer(inputs=inputs)\n","    # Instantiate the stack of residual units\n","    for stack in range(3):\n","        for res_block in range(num_res_blocks):\n","            strides = 1\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                strides = 2  # downsample\n","            y = resnet_layer(inputs=x,\n","                             num_filters=num_filters,\n","                             strides=strides)\n","            y = resnet_layer(inputs=y,\n","                             num_filters=num_filters,\n","                             activation=None)\n","            if stack > 0 and res_block == 0:  # first layer but not first stack\n","                # linear projection residual shortcut connection to match\n","                # changed dims\n","                x = resnet_layer(inputs=x,\n","                                 num_filters=num_filters,\n","                                 kernel_size=1,\n","                                 strides=strides,\n","                                 activation=None,\n","                                 batch_normalization=False)\n","            x = keras.layers.add([x, y])\n","            x = Activation('relu')(x)\n","        num_filters *= 2\n","\n","    # Add classifier on top.\n","    # v1 does not use BN after last shortcut connection-ReLU\n","    x = AveragePooling2D(pool_size=8)(x)\n","    y = Flatten()(x)\n","    outputs = Dense(num_classes,\n","                    activation='softmax',\n","                    kernel_initializer='he_normal')(y)\n","    # Instantiate model.\n","    model = Model(inputs=inputs, outputs=outputs)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KI--slgF5-D0"},"outputs":[],"source":["def lr_schedule(epoch):\n","    \"\"\"Learning Rate Schedule\n","\n","    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n","    Called automatically every epoch as part of callbacks during training.\n","\n","    # Arguments\n","        epoch (int): The number of epochs\n","\n","    # Returns\n","        lr (float32): learning rate\n","    \"\"\"\n","    lr = 1e-3\n","    if epoch > 180:\n","        lr *= 0.5e-3\n","    elif epoch > 160:\n","        lr *= 1e-3\n","    elif epoch > 120:\n","        lr *= 1e-2\n","    elif epoch > 80:\n","        lr *= 1e-1\n","    print('Learning rate: ', lr)\n","    return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jtXh5ajC6AKC"},"outputs":[],"source":["def tflite_conv(model,path,quant=False):\n","    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","    if quant == True:\n","        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","    pruned_tflite_model = converter.convert()\n","    with open(path, 'wb') as f:\n","      f.write(pruned_tflite_model)\n","    print('Saved pruned TFLite model to:',path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GQ4jU6PM6CJV"},"outputs":[],"source":["def get_gzipped_model_size(file):\n","  # Returns size of gzipped model, in bytes.\n","    import os\n","    import zipfile\n","\n","    _, zipped_file = tempfile.mkstemp('.zip')\n","    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","        f.write(file)\n","\n","    return os.path.getsize(zipped_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqbzgNzq6EQB","outputId":"b09f407c-f067-4af3-cf3c-e79a3efa8d50"},"outputs":[{"data":{"text/plain":["1"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["strategy.num_replicas_in_sync"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J7YmlsR26M8G"},"outputs":[],"source":["def resnet_training(x_train,y_train,x_test, y_test,layers,frequency,\\\n","                    initial_sparsity,final_sparsity,gpu=\"T4\",\\\n","                    const=True, poly=False,file_name='cifar10_test1',\\\n","                    num_classes=10,begin_step=0,end_step='default'):\n","\n","    # Default parameters\n","    batch_size = 128 * strategy.num_replicas_in_sync \n","    epochs = 1#300\n","    data_augmentation = True\n","    n = layers\n","\n","    # Computed depth from supplied model parameter n\n","    depth = n * 6 + 2\n","\n","    # Input image dimensions.\n","    input_shape = x_train.shape[1:]\n","\n","    # Subtracting pixel mean improves accuracy\n","    x_train_mean = np.mean(x_train, axis=0)\n","    x_train -= x_train_mean\n","    x_test -= x_train_mean\n","\n","    print('x_train shape:', x_train.shape)\n","    print(x_train.shape[0], 'train samples')\n","    print(x_test.shape[0], 'test samples')\n","    print('y_train shape:', y_train.shape)\n","\n","    ####Changes start#####\n","    num_images = x_train.shape[0] #* (1 - validation_split)\n","\n","    if end_step == 'default':\n","        end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n","\n","    #hyperparameters: initial_sparsity=0.50, final_sparsity=0.80\n","    if poly:\n","        pruning_params = {\n","              'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=initial_sparsity,\n","                                                                       final_sparsity=final_sparsity,\n","                                                                       begin_step=begin_step,\n","                                                                       end_step=end_step,\n","                                                                      frequency=frequency)\n","        }\n","    if const:\n","            pruning_params = {\n","              'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(target_sparsity=final_sparsity,\n","                                                                       begin_step=begin_step,\n","                                                                       end_step=end_step,\n","                                                                       frequency=frequency)\n","        }\n","\n","    prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n","    with strategy.scope():\n","        model = resnet_v1(input_shape=input_shape, depth=depth,num_classes=num_classes)\n","        model = prune_low_magnitude(model, **pruning_params)    #_for_pruning\n","\n","        model.compile(loss= 'categorical_crossentropy',     #''  tf.  keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","                  optimizer=Adam(lr=lr_schedule(0)),\n","                  metrics=['accuracy'])\n","    ####Changes end#####\n","    model.summary()\n","\n","    # Prepare model model saving directory.\n","    save_dir = os.path.join(os.getcwd(), 'saved_models')\n","    if not os.path.isdir(save_dir):\n","        os.makedirs(save_dir)\n","\n","    model_run=file_name+'_'+str(depth)+'_'+gpu\n","    model_path=model_run+'.h5'\n","    print(\"RRrrrrrR\",model_path)\n","    \n","    filepath = os.path.join(save_dir, model_path)\n","    print(\"RRR\",filepath)\n","    \n","    print(model_run)\n","\n","    # Prepare callbacks for model saving and for learning rate adjustment.\n","    checkpoint = ModelCheckpoint(filepath=filepath,\n","                                 monitor='val_acc',\n","                                 verbose=1,\n","                                 save_best_only=True)\n","\n","    lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","    lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n","                                   cooldown=0,\n","                                   patience=5,\n","                                   min_lr=0.5e-6)\n","    logdir = tempfile.mkdtemp()\n","    time_callback = TimeHistory()\n","    logname='/home/jupyter/final_proj/log_'+model_run+'.csv'\n","    csv_logger = CSVLogger(logname, append=True, separator=';')\n","    callbacks = [checkpoint, lr_reducer, lr_scheduler, csv_logger, time_callback, pruning_callbacks.UpdatePruningStep(), tfmot.sparsity.keras.PruningSummaries(log_dir=logdir)]\n","\n","    st = time.time()\n","    ######################## no augmentation################\n","    # model.fit(x_train, y_train,\n","    #           batch_size=batch_size,\n","    #           epochs=epochs,\n","    #           validation_data=(x_test, y_test),\n","    #           shuffle=True,\n","    #           callbacks=callbacks)\n","    ######################## no augmentation################\n","\n","    ########################augmentation################\n","    datagen = ImageDataGenerator(\n","          # set input mean to 0 over the dataset\n","          featurewise_center=False,\n","          # set each sample mean to 0\n","          samplewise_center=False,\n","          # divide inputs by std of dataset\n","          featurewise_std_normalization=False,\n","          # divide each input by its std\n","          samplewise_std_normalization=False,\n","          # apply ZCA whitening\n","          zca_whitening=False,\n","          # epsilon for ZCA whitening\n","          zca_epsilon=1e-06,\n","          # randomly rotate images in the range (deg 0 to 180)\n","          rotation_range=0,\n","          # randomly shift images horizontally\n","          width_shift_range=0.1,\n","          # randomly shift images vertically\n","          height_shift_range=0.1,\n","          # set range for random shear\n","          shear_range=0.,\n","          # set range for random zoom\n","          zoom_range=0.,\n","          # set range for random channel shifts\n","          channel_shift_range=0.,\n","          # set mode for filling points outside the input boundaries\n","          fill_mode='nearest',\n","          # value used for fill_mode = \"constant\"\n","          cval=0.,\n","          # randomly flip images\n","          horizontal_flip=True,\n","          # randomly flip images\n","          vertical_flip=False,\n","          # set rescaling factor (applied before any other transformation)\n","          rescale=None,\n","          # set function that will be applied on each input\n","          preprocessing_function=None,\n","          # image data format, either \"channels_first\" or \"channels_last\"\n","          data_format=None,\n","          # fraction of images reserved for validation (strictly between 0 and 1)\n","          validation_split=0.0)\n","          \n","    datagen.fit(x_train)\n","\n","    # Fit the model on the batches generated by datagen.flow().\n","    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n","                        validation_data=(x_test, y_test),\n","                        epochs=epochs, verbose=1, \n","                        callbacks=callbacks)\n","     \n","     ########################augmentation################\n","\n","    %tensorboard --logdir={logdir}\n","    training_time = time.time() - st\n","\n","    print(f\"overall training time is {training_time}\")\n","    epoch_times = time_callback.times\n","    print(f\"each epoch training time is {epoch_times}\")\n","\n","    # Score trained model.\n","    scores = model.evaluate(x_test, y_test, verbose=1)\n","    print('Test loss:', scores[0])\n","    print('Test accuracy:', scores[1])\n","    print(\"tt\",save_dir+'/'+model_run)\n","    \n","    #save standard model \n","    model.save(save_dir+'/'+model_path)\n","    \n","    #saving data \n","    with open(model_run+'.pickle', 'wb') as handle:\n","        pickle.dump([training_time,epoch_times,scores[0],scores[1]], handle)\n","\n","    #save pruned model\n","    model_for_export = tfmot.sparsity.keras.strip_pruning(model)\n","    pruned_keras_file = save_dir+'/PRUNE_'+model_path\n","    keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n","    print('Saved pruned Keras model to:', pruned_keras_file)\n","    \n","    #convert to tflite+ save\n","    pruned_tflite_file=save_dir+'/lite_PRUNE_'+model_path\n","    tflite_conv(model,pruned_tflite_file)\n","    \n","    #save to tf lite + qaunt\n","    pruned_tflite_quant_file=save_dir+'/lite_quant_PRUNE_'+model_path\n","    tflite_conv(model,pruned_tflite_quant_file,quant=True)\n","    \n","    pruned=get_gzipped_model_size(pruned_keras_file)\n","    tflite_pruned=get_gzipped_model_size(pruned_tflite_file)\n","    tflite_quant_pruned=get_gzipped_model_size(pruned_tflite_quant_file)\n","    \n","    \n","    print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (pruned))\n","    print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (tflite_pruned))\n","    print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\" % (tflite_quant_pruned))\n","    \n","    with open(model_run+'.pickle', 'wb') as handle:\n","        pickle.dump([training_time,epoch_times,scores[0],scores[1],pruned,tflite_pruned,tflite_quant_pruned], handle)\n","\n","    return(model,model_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XRxSJSxR6QKd"},"outputs":[],"source":["# Load the CIFAR100 data.\n","(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n","# Normalize data.\n","X_train = X_train.astype('float32') / 255\n","X_test = X_test.astype('float32') / 255\n","# Convert class vectors to binary class matrices.\n","Y_train = keras.utils.to_categorical(Y_train)\n","Y_test = keras.utils.to_categorical(Y_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVVvxo1P6T2o","outputId":"100386a8-40c4-4576-b759-69831fcee326"},"outputs":[{"name":"stdout","output_type":"stream","text":["x_train shape: (50000, 32, 32, 3)\n","50000 train samples\n","10000 test samples\n","y_train shape: (50000, 100)\n","Learning rate:  0.001\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n","                                                                                                  \n"," prune_low_magnitude_conv2d_45   (None, 32, 32, 16)  882         ['input_2[0][0]']                \n"," (PruneLowMagnitude)                                                                              \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_45[0\n"," alization_43 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n"," _43 (PruneLowMagnitude)                                         lization_43[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_46   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             43[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_46[0\n"," alization_44 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n"," _44 (PruneLowMagnitude)                                         lization_44[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_47   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             44[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_47[0\n"," alization_45 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_21 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                43[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_45[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_21[0][0\n"," _45 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_48   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             45[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_48[0\n"," alization_46 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n"," _46 (PruneLowMagnitude)                                         lization_46[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_49   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             46[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_49[0\n"," alization_47 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_22 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                45[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_47[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_22[0][0\n"," _47 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_50   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             47[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_50[0\n"," alization_48 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_batch_norma\n"," _48 (PruneLowMagnitude)                                         lization_48[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_51   (None, 32, 32, 16)  4626        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             48[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 32, 32, 16)  65          ['prune_low_magnitude_conv2d_51[0\n"," alization_49 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_23 (Pr  (None, 32, 32, 16)  1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                47[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_49[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 32, 32, 16)  1           ['prune_low_magnitude_add_23[0][0\n"," _49 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_52   (None, 16, 16, 32)  9250        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             49[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_52[0\n"," alization_50 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n"," _50 (PruneLowMagnitude)                                         lization_50[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_53   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             50[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_conv2d_54   (None, 16, 16, 32)  1058        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             49[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_53[0\n"," alization_51 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_24 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_conv2d_54[0\n"," uneLowMagnitude)                                                ][0]',                           \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_51[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_24[0][0\n"," _51 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_55   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             51[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_55[0\n"," alization_52 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n"," _52 (PruneLowMagnitude)                                         lization_52[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_56   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             52[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_56[0\n"," alization_53 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_25 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                51[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_53[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_25[0][0\n"," _53 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_57   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             53[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_57[0\n"," alization_54 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_batch_norma\n"," _54 (PruneLowMagnitude)                                         lization_54[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_58   (None, 16, 16, 32)  18466       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             54[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 16, 16, 32)  129         ['prune_low_magnitude_conv2d_58[0\n"," alization_55 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_26 (Pr  (None, 16, 16, 32)  1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                53[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_55[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 16, 16, 32)  1           ['prune_low_magnitude_add_26[0][0\n"," _55 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_59   (None, 8, 8, 64)    36930       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             55[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_59[0\n"," alization_56 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n"," _56 (PruneLowMagnitude)                                         lization_56[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_60   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             56[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_conv2d_61   (None, 8, 8, 64)    4162        ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             55[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_60[0\n"," alization_57 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_27 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_conv2d_61[0\n"," uneLowMagnitude)                                                ][0]',                           \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_57[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_27[0][0\n"," _57 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_62   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             57[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_62[0\n"," alization_58 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n"," _58 (PruneLowMagnitude)                                         lization_58[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_63   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             58[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_63[0\n"," alization_59 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_28 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                57[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_59[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_28[0][0\n"," _59 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_64   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             59[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_64[0\n"," alization_60 (PruneLowMagnitud                                  ][0]']                           \n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]},{"name":"stdout","output_type":"stream","text":[" e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_batch_norma\n"," _60 (PruneLowMagnitude)                                         lization_60[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_conv2d_65   (None, 8, 8, 64)    73794       ['prune_low_magnitude_activation_\n"," (PruneLowMagnitude)                                             60[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_batch_norm  (None, 8, 8, 64)    257         ['prune_low_magnitude_conv2d_65[0\n"," alization_61 (PruneLowMagnitud                                  ][0]']                           \n"," e)                                                                                               \n","                                                                                                  \n"," prune_low_magnitude_add_29 (Pr  (None, 8, 8, 64)    1           ['prune_low_magnitude_activation_\n"," uneLowMagnitude)                                                59[0][0]',                       \n","                                                                  'prune_low_magnitude_batch_norma\n","                                                                 lization_61[0][0]']              \n","                                                                                                  \n"," prune_low_magnitude_activation  (None, 8, 8, 64)    1           ['prune_low_magnitude_add_29[0][0\n"," _61 (PruneLowMagnitude)                                         ]']                              \n","                                                                                                  \n"," prune_low_magnitude_average_po  (None, 1, 1, 64)    1           ['prune_low_magnitude_activation_\n"," oling2d_1 (PruneLowMagnitude)                                   61[0][0]']                       \n","                                                                                                  \n"," prune_low_magnitude_flatten_1   (None, 64)          1           ['prune_low_magnitude_average_poo\n"," (PruneLowMagnitude)                                             ling2d_1[0][0]']                 \n","                                                                                                  \n"," prune_low_magnitude_dense_1 (P  (None, 100)         12902       ['prune_low_magnitude_flatten_1[0\n"," runeLowMagnitude)                                               ][0]']                           \n","                                                                                                  \n","==================================================================================================\n","Total params: 557,041\n","Trainable params: 278,916\n","Non-trainable params: 278,125\n","__________________________________________________________________________________________________\n","RRrrrrrR resnet_super_twenty_20_k80.h5\n","RRR /home/jupyter/final_proj/saved_models/resnet_super_twenty_20_k80.h5\n","resnet_super_twenty_20_k80\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:153: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","2022-12-16 22:43:43.912587: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n","op: \"FlatMapDataset\"\n","input: \"TensorDataset/_1\"\n","attr {\n","  key: \"Targuments\"\n","  value {\n","    list {\n","    }\n","  }\n","}\n","attr {\n","  key: \"_cardinality\"\n","  value {\n","    i: -2\n","  }\n","}\n","attr {\n","  key: \"f\"\n","  value {\n","    func {\n","      name: \"__inference_Dataset_flat_map_flat_map_fn_428000\"\n","    }\n","  }\n","}\n","attr {\n","  key: \"metadata\"\n","  value {\n","    s: \"\\n\\021FlatMapDataset:59\"\n","  }\n","}\n","attr {\n","  key: \"output_shapes\"\n","  value {\n","    list {\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","        dim {\n","          size: -1\n","        }\n","        dim {\n","          size: -1\n","        }\n","        dim {\n","          size: -1\n","        }\n","      }\n","      shape {\n","        dim {\n","          size: -1\n","        }\n","        dim {\n","          size: -1\n","        }\n","      }\n","    }\n","  }\n","}\n","attr {\n","  key: \"output_types\"\n","  value {\n","    list {\n","      type: DT_FLOAT\n","      type: DT_FLOAT\n","    }\n","  }\n","}\n","experimental_type {\n","  type_id: TFT_PRODUCT\n","  args {\n","    type_id: TFT_DATASET\n","    args {\n","      type_id: TFT_PRODUCT\n","      args {\n","        type_id: TFT_TENSOR\n","        args {\n","          type_id: TFT_FLOAT\n","        }\n","      }\n","      args {\n","        type_id: TFT_TENSOR\n","        args {\n","          type_id: TFT_FLOAT\n","        }\n","      }\n","    }\n","  }\n","}\n",". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n"]},{"name":"stdout","output_type":"stream","text":["Learning rate:  0.001\n","  6/391 [..............................] - ETA: 19s - loss: 7.3628 - accuracy: 0.0091      WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0454s vs `on_train_batch_end` time: 0.0845s). Check your callbacks.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0454s vs `on_train_batch_end` time: 0.0845s). Check your callbacks.\n"]},{"name":"stdout","output_type":"stream","text":["391/391 [==============================] - ETA: 0s - loss: 4.2706 - accuracy: 0.0859WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"]},{"name":"stdout","output_type":"stream","text":["391/391 [==============================] - 54s 81ms/step - loss: 4.2706 - accuracy: 0.0859 - val_loss: 4.0053 - val_accuracy: 0.1106 - lr: 0.0010\n"]},{"data":{"text/html":["\n","      <iframe id=\"tensorboard-frame-c09882b25139db37\" width=\"100%\" height=\"800\" frameborder=\"0\">\n","      </iframe>\n","      <script>\n","        (function() {\n","          const frame = document.getElementById(\"tensorboard-frame-c09882b25139db37\");\n","          const url = new URL(\"/proxy/6007/\", window.location);\n","          const port = 0;\n","          if (port) {\n","            url.port = port;\n","          }\n","          frame.src = url;\n","        })();\n","      </script>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["overall training time is 58.05539274215698\n","each epoch training time is [53.77062225341797]\n","313/313 [==============================] - 3s 8ms/step - loss: 4.0053 - accuracy: 0.1106\n","Test loss: 4.005294322967529\n","Test accuracy: 0.11060000211000443\n","tt /home/jupyter/final_proj/saved_models/resnet_super_twenty_20_k80\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stdout","output_type":"stream","text":["Saved pruned Keras model to: /home/jupyter/final_proj/saved_models/PRUNE_resnet_super_twenty_20_k80.h5\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as conv2d_45_layer_call_fn, conv2d_45_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, activation_43_layer_call_fn, activation_43_layer_call_and_return_conditional_losses while saving (showing 5 of 123). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpq4by6784/assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: /tmp/tmpq4by6784/assets\n"]}],"source":["layers = [3, 7]\n","names = [\"twenty\", \"forty\"]\n","for x in range(2):\n","    name=\"resnet_super_\"+names[x]\n","    model1 = resnet_training(X_train,Y_train,X_test, Y_test,layers=layers[x],frequency=100,\\\n","                    initial_sparsity = 0.5, final_sparsity=0.6,gpu=\"k80\",\\\n","                    const=False, poly=True,file_name=name,\\\n","                    num_classes=100,begin_step=0,end_step='default')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yC-PpggqHfTm"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"TensorFlow 2 (Local)","language":"python","name":"local-tf2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}